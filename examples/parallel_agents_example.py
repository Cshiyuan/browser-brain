#!/usr/bin/env python3
"""
Browser-Use Parallel Agents ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¹¶è¡Œæ‰§è¡ŒåŠŸèƒ½åŒæ—¶è¿è¡Œå¤šä¸ªç‹¬ç«‹ä»»åŠ¡
"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.scrapers.browser_use_scraper import BrowserUseScraper
from app.utils.logger import setup_logger

logger = setup_logger(__name__)


async def example_1_basic_parallel():
    """
    ç¤ºä¾‹1: åŸºç¡€å¹¶è¡Œä»»åŠ¡æ‰§è¡Œ

    åœºæ™¯: åŒæ—¶åœ¨3ä¸ªç½‘ç«™æœç´¢ä¸åŒå†…å®¹
    """
    logger.info("=" * 60)
    logger.info("ç¤ºä¾‹1: åŸºç¡€å¹¶è¡Œä»»åŠ¡æ‰§è¡Œ")
    logger.info("=" * 60)

    # å®šä¹‰3ä¸ªå®Œå…¨ç‹¬ç«‹çš„ä»»åŠ¡
    tasks = [
        "è®¿é—®å°çº¢ä¹¦ https://www.xiaohongshu.com å¹¶æœç´¢'åŒ—äº¬æ•…å®«'ï¼Œæå–ç¬¬ä¸€ä¸ªç¬”è®°æ ‡é¢˜",
        "è®¿é—®å°çº¢ä¹¦ https://www.xiaohongshu.com å¹¶æœç´¢'ä¸Šæµ·å¤–æ»©'ï¼Œæå–ç¬¬ä¸€ä¸ªç¬”è®°æ ‡é¢˜",
        "è®¿é—®å°çº¢ä¹¦ https://www.xiaohongshu.com å¹¶æœç´¢'æˆéƒ½ç†ŠçŒ«åŸºåœ°'ï¼Œæå–ç¬¬ä¸€ä¸ªç¬”è®°æ ‡é¢˜"
    ]

    # å¹¶è¡Œæ‰§è¡Œï¼ˆ3ä¸ªæµè§ˆå™¨åŒæ—¶è¿è¡Œï¼‰
    results = await BrowserUseScraper.run_parallel(
        tasks=tasks,
        max_steps=10,
        headless=False  # æ˜¾ç¤ºæµè§ˆå™¨ï¼Œè§‚å¯Ÿå¹¶è¡Œæ‰§è¡Œ
    )

    # æ‰“å°ç»“æœ
    for result in results:
        logger.info(f"ä»»åŠ¡ {result['task_index']}: {result['status']}")
        if result['status'] == 'success':
            logger.info(f"  æ•°æ®: {result.get('data', 'N/A')}")
        else:
            logger.error(f"  é”™è¯¯: {result.get('error', 'Unknown')}")


async def example_2_multi_attraction_scraping():
    """
    ç¤ºä¾‹2: å¹¶è¡Œçˆ¬å–å¤šä¸ªæ™¯ç‚¹ä¿¡æ¯

    åœºæ™¯: åŒæ—¶çˆ¬å–5ä¸ªä¸åŒæ™¯ç‚¹çš„å°çº¢ä¹¦ç¬”è®°
    """
    logger.info("=" * 60)
    logger.info("ç¤ºä¾‹2: å¹¶è¡Œçˆ¬å–å¤šä¸ªæ™¯ç‚¹")
    logger.info("=" * 60)

    attractions = ["åŒ—äº¬æ•…å®«", "é•¿åŸ", "é¢å’Œå›­", "å¤©å›", "åœ†æ˜å›­"]

    # ä¸ºæ¯ä¸ªæ™¯ç‚¹ç”Ÿæˆä»»åŠ¡
    tasks = [
        f"è®¿é—®å°çº¢ä¹¦æœç´¢'{attr}'ï¼Œæå–æœ€çƒ­é—¨çš„1æ¡ç¬”è®°çš„æ ‡é¢˜å’Œä½œè€…"
        for attr in attractions
    ]

    # å¯ç”¨Fast ModeåŠ é€Ÿï¼ˆå¹¶è¡Œ + Fast Mode = è¶…å¿«ï¼‰
    results = await BrowserUseScraper.run_parallel(
        tasks=tasks,
        max_steps=15,
        headless=True,
        fast_mode=True  # æ¯ä¸ªä»»åŠ¡éƒ½ä½¿ç”¨Fast Mode
    )

    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r['status'] == 'success')
    logger.info(f"âœ… æˆåŠŸçˆ¬å– {success_count}/{len(attractions)} ä¸ªæ™¯ç‚¹")


async def example_3_cross_platform_search():
    """
    ç¤ºä¾‹3: è·¨å¹³å°å¹¶è¡Œæœç´¢

    åœºæ™¯: åœ¨ä¸åŒå¹³å°åŒæ—¶æœç´¢åŒä¸€ä¸»é¢˜
    """
    logger.info("=" * 60)
    logger.info("ç¤ºä¾‹3: è·¨å¹³å°å¹¶è¡Œæœç´¢")
    logger.info("=" * 60)

    keyword = "åŒ—äº¬æ—…æ¸¸æ”»ç•¥"

    tasks = [
        f"åœ¨å°çº¢ä¹¦æœç´¢'{keyword}'ï¼Œæå–ç¬¬ä¸€ä¸ªç»“æœ",
        f"è®¿é—®çŸ¥ä¹ https://www.zhihu.com æœç´¢'{keyword}'ï¼Œæå–ç¬¬ä¸€ä¸ªé—®é¢˜æ ‡é¢˜",
        f"è®¿é—®ç™¾åº¦ https://www.baidu.com æœç´¢'{keyword}'ï¼Œæå–å‰3ä¸ªæœç´¢ç»“æœæ ‡é¢˜"
    ]

    results = await BrowserUseScraper.run_parallel(
        tasks=tasks,
        max_steps=20,
        headless=False
    )

    # å¯¹æ¯”ä¸åŒå¹³å°çš„ç»“æœ
    for result in results:
        logger.info(f"å¹³å°ä»»åŠ¡ {result['task_index']}: {result['status']}")


async def example_4_performance_comparison():
    """
    ç¤ºä¾‹4: ä¸²è¡Œ vs å¹¶è¡Œæ€§èƒ½å¯¹æ¯”

    å¯¹æ¯”ä¸²è¡Œæ‰§è¡Œå’Œå¹¶è¡Œæ‰§è¡Œçš„æ—¶é—´å·®å¼‚
    """
    logger.info("=" * 60)
    logger.info("ç¤ºä¾‹4: ä¸²è¡Œ vs å¹¶è¡Œæ€§èƒ½å¯¹æ¯”")
    logger.info("=" * 60)

    import time

    tasks = [
        "è®¿é—®å°çº¢ä¹¦æœç´¢'åŒ—äº¬'ï¼Œæå–ç¬¬ä¸€ä¸ªç»“æœ",
        "è®¿é—®å°çº¢ä¹¦æœç´¢'ä¸Šæµ·'ï¼Œæå–ç¬¬ä¸€ä¸ªç»“æœ",
        "è®¿é—®å°çº¢ä¹¦æœç´¢'å¹¿å·'ï¼Œæå–ç¬¬ä¸€ä¸ªç»“æœ"
    ]

    # æ–¹æ¡ˆ1: ä¸²è¡Œæ‰§è¡Œ
    logger.info("ğŸ“Š æµ‹è¯•æ–¹æ¡ˆ1: ä¸²è¡Œæ‰§è¡Œ")
    start = time.time()

    for idx, task in enumerate(tasks, 1):
        scraper = BrowserUseScraper(headless=True, fast_mode=True)
        try:
            result = await scraper.scrape_with_task(task, max_steps=10)
            logger.info(f"  ä»»åŠ¡{idx}: {result['status']}")
        finally:
            await scraper.close()

    serial_time = time.time() - start
    logger.info(f"ä¸²è¡Œæ‰§è¡Œè€—æ—¶: {serial_time:.1f}ç§’")

    # æ–¹æ¡ˆ2: å¹¶è¡Œæ‰§è¡Œ
    logger.info("ğŸ“Š æµ‹è¯•æ–¹æ¡ˆ2: å¹¶è¡Œæ‰§è¡Œ")
    start = time.time()

    results = await BrowserUseScraper.run_parallel(
        tasks=tasks,
        max_steps=10,
        headless=True,
        fast_mode=True
    )

    parallel_time = time.time() - start
    logger.info(f"å¹¶è¡Œæ‰§è¡Œè€—æ—¶: {parallel_time:.1f}ç§’")

    # å¯¹æ¯”
    speedup = serial_time / parallel_time if parallel_time > 0 else 0
    logger.info(f"ğŸš€ é€Ÿåº¦æå‡: {speedup:.1f}x")


async def example_5_error_handling():
    """
    ç¤ºä¾‹5: å¹¶è¡Œä»»åŠ¡çš„é”™è¯¯å¤„ç†

    åœºæ™¯: éƒ¨åˆ†ä»»åŠ¡å¤±è´¥ä¸å½±å“å…¶ä»–ä»»åŠ¡
    """
    logger.info("=" * 60)
    logger.info("ç¤ºä¾‹5: å¹¶è¡Œä»»åŠ¡é”™è¯¯å¤„ç†")
    logger.info("=" * 60)

    tasks = [
        "è®¿é—®å°çº¢ä¹¦æœç´¢'åŒ—äº¬'ï¼Œæå–æ•°æ®",
        "è®¿é—®ä¸€ä¸ªä¸å­˜åœ¨çš„ç½‘ç«™ https://invalid-url-12345.com",  # æ•…æ„å¤±è´¥
        "è®¿é—®å°çº¢ä¹¦æœç´¢'ä¸Šæµ·'ï¼Œæå–æ•°æ®"
    ]

    results = await BrowserUseScraper.run_parallel(
        tasks=tasks,
        max_steps=10,
        headless=True
    )

    # åˆ†æç»“æœ
    for result in results:
        status_icon = "âœ…" if result['status'] == 'success' else "âŒ"
        logger.info(f"{status_icon} ä»»åŠ¡ {result['task_index']}: {result['status']}")

        if result['status'] != 'success':
            logger.warning(f"  é”™è¯¯è¯¦æƒ…: {result.get('error', 'Unknown')}")


async def example_6_resource_optimization():
    """
    ç¤ºä¾‹6: èµ„æºä¼˜åŒ–ç­–ç•¥

    åœºæ™¯: æ ¹æ®ç³»ç»Ÿèµ„æºåŠ¨æ€è°ƒæ•´å¹¶è¡Œæ•°é‡
    """
    logger.info("=" * 60)
    logger.info("ç¤ºä¾‹6: èµ„æºä¼˜åŒ–ç­–ç•¥")
    logger.info("=" * 60)

    # å‡è®¾æœ‰10ä¸ªæ™¯ç‚¹éœ€è¦çˆ¬å–
    all_attractions = [
        "åŒ—äº¬æ•…å®«", "é•¿åŸ", "é¢å’Œå›­", "å¤©å›", "åœ†æ˜å›­",
        "ä¸Šæµ·å¤–æ»©", "ä¸œæ–¹æ˜ç ", "è±«å›­", "å—äº¬è·¯", "åŸéšåº™"
    ]

    # ç­–ç•¥: æ¯æ¬¡å¹¶è¡Œ3ä¸ªï¼ˆæ ¹æ®ç³»ç»Ÿå†…å­˜å’ŒCPUè°ƒæ•´ï¼‰
    batch_size = 3
    all_results = []

    for i in range(0, len(all_attractions), batch_size):
        batch = all_attractions[i:i + batch_size]
        logger.info(f"ğŸ”„ å¤„ç†ç¬¬ {i // batch_size + 1} æ‰¹: {batch}")

        tasks = [
            f"åœ¨å°çº¢ä¹¦æœç´¢'{attr}'ï¼Œæå–ç¬¬ä¸€ä¸ªç¬”è®°æ ‡é¢˜"
            for attr in batch
        ]

        batch_results = await BrowserUseScraper.run_parallel(
            tasks=tasks,
            max_steps=10,
            headless=True,
            fast_mode=True
        )

        all_results.extend(batch_results)

        # æ‰¹æ¬¡é—´ä¼‘æ¯ï¼ˆå¯é€‰ï¼‰
        if i + batch_size < len(all_attractions):
            logger.info("â¸ï¸  æ‰¹æ¬¡é—´ä¼‘æ¯5ç§’...")
            await asyncio.sleep(5)

    logger.info(f"âœ… å…¨éƒ¨å®Œæˆ: {len(all_results)} ä¸ªä»»åŠ¡")


async def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    examples = [
        ("åŸºç¡€å¹¶è¡Œæ‰§è¡Œ", example_1_basic_parallel),
        ("å¹¶è¡Œçˆ¬å–å¤šä¸ªæ™¯ç‚¹", example_2_multi_attraction_scraping),
        ("è·¨å¹³å°å¹¶è¡Œæœç´¢", example_3_cross_platform_search),
        ("æ€§èƒ½å¯¹æ¯”", example_4_performance_comparison),
        ("é”™è¯¯å¤„ç†", example_5_error_handling),
        ("èµ„æºä¼˜åŒ–", example_6_resource_optimization),
    ]

    logger.info("ğŸ¯ Browser-Use Parallel Agents ç¤ºä¾‹é›†")
    logger.info(f"å…± {len(examples)} ä¸ªç¤ºä¾‹\n")

    for idx, (name, func) in enumerate(examples, 1):
        logger.info(f"\n{'='*60}")
        logger.info(f"è¿è¡Œç¤ºä¾‹ {idx}/{len(examples)}: {name}")
        logger.info(f"{'='*60}\n")

        try:
            await func()
            logger.info(f"âœ… ç¤ºä¾‹ {idx} å®Œæˆ\n")
        except Exception as e:
            logger.exception(f"âŒ ç¤ºä¾‹ {idx} å¤±è´¥: {e}\n")

        # ç¤ºä¾‹é—´é—´éš”
        await asyncio.sleep(2)

    logger.info("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ")


if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    asyncio.run(main())

    # æˆ–è€…å•ç‹¬è¿è¡ŒæŸä¸ªç¤ºä¾‹
    # asyncio.run(example_1_basic_parallel())
