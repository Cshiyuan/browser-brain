"""æµ‹è¯•çˆ¬è™«åˆå§‹åŒ–å’Œæ—¥å¿—ç³»ç»Ÿ - å¿«é€Ÿæµ‹è¯•ï¼ˆä¸å®é™…çˆ¬å–ï¼‰"""
import asyncio
from app.scrapers.xhs_scraper import XHSScraper
from app.scrapers.official_scraper import OfficialScraper
from app.utils.logger import setup_logger

logger = setup_logger(__name__)

async def test_scrapers_init():
    """æµ‹è¯•çˆ¬è™«åˆå§‹åŒ–æµç¨‹"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•çˆ¬è™«åˆå§‹åŒ–å’Œæ—¥å¿—ç³»ç»Ÿ")
    logger.info("=" * 60)

    # æµ‹è¯•1: å°çº¢ä¹¦çˆ¬è™«åˆå§‹åŒ–
    logger.info("\nğŸ“ æµ‹è¯• 1: XHSScraper åˆå§‹åŒ–")
    try:
        xhs_scraper = XHSScraper(headless=False)
        logger.info("âœ… XHSScraper åˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"   - LLM Provider: å·²é…ç½®")
        logger.info(f"   - Headlessæ¨¡å¼: {xhs_scraper.headless}")
        logger.info(f"   - Browser Profile: å·²åˆ›å»º")
    except Exception as e:
        logger.error(f"âŒ XHSScraper åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    # æµ‹è¯•2: å®˜ç½‘çˆ¬è™«åˆå§‹åŒ–
    logger.info("\nğŸ“ æµ‹è¯• 2: OfficialScraper åˆå§‹åŒ–")
    try:
        official_scraper = OfficialScraper(headless=False)
        logger.info("âœ… OfficialScraper åˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"   - LLM Provider: å·²é…ç½®")
        logger.info(f"   - Headlessæ¨¡å¼: {official_scraper.headless}")
        logger.info(f"   - Browser Profile: å·²åˆ›å»º")
    except Exception as e:
        logger.error(f"âŒ OfficialScraper åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    # æµ‹è¯•3: æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
    logger.info("\nğŸ“ æµ‹è¯• 3: æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ç»“æ„")
    import os
    from pathlib import Path

    log_dirs = ["logs/scrapers", "logs/agents", "logs/main"]
    for log_dir in log_dirs:
        if Path(log_dir).exists():
            files = list(Path(log_dir).glob("*.log"))
            logger.info(f"âœ… {log_dir}: {len(files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
            for f in files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                size = f.stat().st_size
                logger.info(f"   - {f.name} ({size} bytes)")
        else:
            logger.warning(f"âš ï¸  {log_dir}: ç›®å½•ä¸å­˜åœ¨")

    logger.info("\n" + "=" * 60)
    logger.info("ğŸ‰ åˆå§‹åŒ–æµ‹è¯•å®Œæˆ!")
    logger.info("=" * 60)

    print("\n\nğŸ’¡ è¯·æŸ¥çœ‹ä»¥ä¸‹æ—¥å¿—æ–‡ä»¶éªŒè¯å®Œæ•´çš„è°ƒç”¨æµç¨‹:")
    print("   ğŸ“‚ logs/scrapers/xhs_scraper_20251005.log")
    print("   ğŸ“‚ logs/scrapers/official_scraper_20251005.log")
    print("   ğŸ“‚ logs/scrapers/browser_use_scraper_20251005.log")
    print("\n   æ¯ä¸ªæ—¥å¿—åº”åŒ…å«:")
    print("   âœ“ [æ–‡ä»¶å:è¡Œå·]")
    print("   âœ“ å‡½æ•°å()")
    print("   âœ“ ğŸ“ STEP æ ‡è®°")
    print("   âœ“ è¯¦ç»†çš„åˆå§‹åŒ–æµç¨‹")

if __name__ == "__main__":
    asyncio.run(test_scrapers_init())
