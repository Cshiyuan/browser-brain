"""åŸºäºBrowser-Useçš„å®˜ç½‘AIçˆ¬è™«"""
from typing import List, Optional

from app.scrapers.browser_use_scraper import BrowserUseScraper
from app.scrapers.models import OfficialInfoOutput
from app.models.attraction import OfficialInfo, XHSNote
from app.models.prompts import OfficialPrompts
from app.utils.logger import setup_logger

logger = setup_logger(__name__)


class OfficialScraper(BrowserUseScraper):
    """åŸºäºBrowser-Useçš„å®˜ç½‘AIçˆ¬è™«"""

    async def get_official_info(
        self,
        attraction_name: str,
        xhs_notes: List[XHSNote]
    ) -> Optional[OfficialInfo]:
        """
        ä½¿ç”¨AIè·å–æ™¯ç‚¹å®˜æ–¹ä¿¡æ¯

        ç­–ç•¥ï¼š
        1. ä¼˜å…ˆä»å°çº¢ä¹¦ç¬”è®°ä¸­æå–çš„é“¾æ¥
        2. å¦‚æœæ²¡æœ‰,ä½¿ç”¨æœç´¢å¼•æ“æŸ¥æ‰¾
        3. AIè‡ªåŠ¨è®¿é—®å®˜ç½‘å¹¶æå–ä¿¡æ¯

        Args:
            attraction_name: æ™¯ç‚¹åç§°
            xhs_notes: å°çº¢ä¹¦ç¬”è®°åˆ—è¡¨

        Returns:
            å®˜æ–¹ä¿¡æ¯å¯¹è±¡
        """
        logger.info(f"========== å¼€å§‹å®˜ç½‘ä¿¡æ¯çˆ¬å– ==========")
        logger.info(f"ç›®æ ‡æ™¯ç‚¹: {attraction_name}, å‚è€ƒç¬”è®°æ•°: {len(xhs_notes)}")
        logger.info(f"ğŸ“ STEP 1: å‡†å¤‡å®˜ç½‘ä¿¡æ¯çˆ¬å–ä»»åŠ¡ | attraction={attraction_name}")

        # ä»å°çº¢ä¹¦ç¬”è®°ä¸­æ”¶é›†æ‰€æœ‰é“¾æ¥
        collected_links = []
        for note in xhs_notes:
            # å¦‚æœæœ‰ url å­—æ®µ,æ·»åŠ åˆ°é“¾æ¥åˆ—è¡¨
            if note.url:
                collected_links.append(note.url)

        # å»é‡
        collected_links = list(set(collected_links))
        logger.info(f"ä»å°çº¢ä¹¦ç¬”è®°ä¸­æ”¶é›†åˆ° {len(collected_links)} ä¸ªé“¾æ¥")
        logger.debug(f"æ”¶é›†çš„é“¾æ¥: {collected_links[:5]}")

        # ä½¿ç”¨æç¤ºè¯æ¨¡å‹ç”Ÿæˆä»»åŠ¡
        if collected_links:
            task = OfficialPrompts.get_official_info_with_links_task(attraction_name, collected_links)
        else:
            task = OfficialPrompts.get_official_info_without_links_task(attraction_name)

        # ä½¿ç”¨AIæ‰§è¡Œçˆ¬å–
        logger.info("ğŸ“ STEP 2: è°ƒç”¨Browser-Use AIæ‰§è¡Œå®˜ç½‘ä¿¡æ¯çˆ¬å–")
        result = await self.scrape(
            task=task,
            output_model=OfficialInfoOutput,
            max_steps=25
        )

        logger.info(f"ğŸ“ STEP 3: å¤„ç†AIè¿”å›ç»“æœ | status={result['status']}")

        if result["status"] != "success":
            logger.warning(f"âš ï¸  AIè·å–å®˜ç½‘ä¿¡æ¯å¤±è´¥: {result.get('error', 'Unknown error')}")
            logger.warning(f"æ‰§è¡Œæ­¥éª¤æ•°: {result.get('steps', 0)}, è®¿é—®çš„URL: {result.get('urls', [])}")
            return None

        # è½¬æ¢ä¸ºOfficialInfoå¯¹è±¡
        data = result["data"]

        # å¤„ç† AI Agent å¤±è´¥è¿”å› None æˆ–å­—ç¬¦ä¸²çš„æƒ…å†µ
        if data is None or isinstance(data, str):
            logger.warning(f"âš ï¸  AIè¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸æˆ–æ— æ•°æ®: {type(data)}")
            logger.debug(f"åŸå§‹è¿”å›æ•°æ®: {data}")
            return None

        logger.info(f"AIæˆåŠŸè¿”å›å®˜ç½‘ä¿¡æ¯æ•°æ®")
        logger.info("ğŸ“ STEP 4: è½¬æ¢æ•°æ®ä¸ºOfficialInfoå¯¹è±¡")

        official_info = OfficialInfo(
            name=attraction_name,
            website=data.website or "",
            opening_hours=data.opening_hours or "",
            ticket_price=data.ticket_price or "",
            booking_info=data.booking_method or "",
            address=data.address or "",
            phone=data.phone or "",
            description=data.description or ""
        )

        logger.info(f"âœ… æˆåŠŸè·å–å®˜ç½‘ä¿¡æ¯: {attraction_name}")
        logger.debug(f"å®˜ç½‘: {official_info.website}")
        logger.debug(f"åœ°å€: {official_info.address}")
        logger.debug(f"é—¨ç¥¨: {official_info.ticket_price}")
        logger.info(f"========== å®˜ç½‘ä¿¡æ¯çˆ¬å–å®Œæˆ ==========")
        return official_info
