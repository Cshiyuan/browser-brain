"""åŸºäºBrowser-Useçš„å°çº¢ä¹¦AIçˆ¬è™«"""
import asyncio
from typing import List
from datetime import datetime

from app.scrapers.browser_use_scraper import BrowserUseScraper
from app.scrapers.models import XHSNotesCollection, DestinationGuide
from app.models.attraction import XHSNote
from app.utils.logger import setup_logger

logger = setup_logger(__name__)


class XHSScraper(BrowserUseScraper):
    """åŸºäºBrowser-Useçš„å°çº¢ä¹¦AIçˆ¬è™«"""

    async def _handle_manual_intervention(
        self,
        message: str,
        wait_seconds: int = 60,
        prompt_interval: int = 10
    ):
        """
        é€šç”¨äººå·¥ä»‹å…¥å¤„ç†ï¼šæš‚åœç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨å®Œæˆæ“ä½œ

        Args:
            message: æç¤ºæ¶ˆæ¯
            wait_seconds: ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’
            prompt_interval: æç¤ºé—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤10ç§’
        """
        logger.warning(message)
        logger.info(f"â³ ç³»ç»Ÿå°†åœ¨ {wait_seconds} ç§’åè‡ªåŠ¨ç»§ç»­...")

        # å®šæœŸæç¤ºå‰©ä½™æ—¶é—´
        for remaining in range(wait_seconds, 0, -prompt_interval):
            logger.info(f"â±ï¸  å‰©ä½™ç­‰å¾…æ—¶é—´: {remaining} ç§’")
            await asyncio.sleep(min(prompt_interval, remaining))

        logger.info("âœ… ç­‰å¾…ç»“æŸï¼Œç»§ç»­æ‰§è¡Œä»»åŠ¡...")

    async def search_attraction(self, attraction_name: str, max_notes: int = 5) -> List[XHSNote]:
        """
        ä½¿ç”¨AIæœç´¢æ™¯ç‚¹ç›¸å…³ç¬”è®°

        Args:
            attraction_name: æ™¯ç‚¹åç§°
            max_notes: æœ€å¤§ç¬”è®°æ•°é‡

        Returns:
            å°çº¢ä¹¦ç¬”è®°åˆ—è¡¨
        """
        logger.info(f"========== å¼€å§‹å°çº¢ä¹¦çˆ¬å– ==========")
        logger.info(f"ç›®æ ‡æ™¯ç‚¹: {attraction_name}, ç›®æ ‡ç¬”è®°æ•°: {max_notes}")
        logger.info(f"ğŸ“ STEP 1: å‡†å¤‡å°çº¢ä¹¦æœç´¢ä»»åŠ¡ | attraction={attraction_name}, max_notes={max_notes}")

        # æ„å»ºAIä»»åŠ¡æè¿°
        task = f"""
ä»»åŠ¡ï¼šåœ¨å°çº¢ä¹¦æœç´¢"{attraction_name}"ç›¸å…³çš„æ—…æ¸¸ç¬”è®°

å…·ä½“æ­¥éª¤ï¼š
1. è®¿é—®å°çº¢ä¹¦ç½‘ç«™ https://www.xiaohongshu.com
2. ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½(3-5ç§’)
3. åœ¨æœç´¢æ¡†ä¸­è¾“å…¥å…³é”®è¯ï¼š"{attraction_name}"
4. ç‚¹å‡»æœç´¢æˆ–æŒ‰å›è½¦é”®
5. ç­‰å¾…æœç´¢ç»“æœåŠ è½½å®Œæˆ
6. æµè§ˆæœç´¢ç»“æœï¼Œæ‰¾åˆ°å‰{max_notes}ç¯‡ç›¸å…³ç¬”è®°
7. å¯¹äºæ¯ç¯‡ç¬”è®°ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯ï¼š
   - ç¬”è®°æ ‡é¢˜
   - ä½œè€…åç§°
   - ç¬”è®°æ­£æ–‡å†…å®¹ï¼ˆå°½å¯èƒ½å®Œæ•´ï¼‰
   - ç‚¹èµæ•°ã€æ”¶è—æ•°ã€è¯„è®ºæ•°
   - ç¬”è®°ä¸­çš„å›¾ç‰‡URLï¼ˆå‰3å¼ ï¼‰
   - æå–ç¬”è®°ä¸­æåˆ°çš„URLé“¾æ¥ï¼ˆç‰¹åˆ«æ˜¯å®˜ç½‘ã€é¢„è®¢ã€é—¨ç¥¨ç›¸å…³é“¾æ¥ï¼‰
   - è¯†åˆ«å…³é”®è¯ï¼ˆå¦‚ï¼šå®˜ç½‘ã€å®˜æ–¹ç½‘ç«™ã€é¢„è®¢ã€é—¨ç¥¨ã€å¼€æ”¾æ—¶é—´ç­‰ï¼‰

é‡è¦æç¤ºï¼š
- åƒçœŸå®ç”¨æˆ·ä¸€æ ·æ“ä½œï¼Œæ¯æ­¥ä¹‹é—´ç•™æœ‰é—´éš”
- ä¼˜å…ˆé€‰æ‹©ç‚¹èµæ•°å’Œæ”¶è—æ•°è¾ƒé«˜çš„ç¬”è®°
- å¦‚æœé‡åˆ°ç™»å½•è¦æ±‚ï¼Œç›´æ¥åœç•™åœ¨ç™»å½•é¡µé¢ç­‰å¾…ï¼ˆä¸è¦å°è¯•è·³è¿‡æˆ–å…³é—­ç™»å½•çª—å£ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶æš‚åœç­‰å¾…äººå·¥ç™»å½•ï¼‰
- é‡åˆ°éªŒè¯ç æ—¶ï¼Œåœç•™åœ¨éªŒè¯ç é¡µé¢ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶æš‚åœç­‰å¾…äººå·¥å¤„ç†ï¼‰
- å¦‚æœé‡åˆ°ä»»ä½•å¼¹çª—æˆ–å¼•å¯¼ï¼Œå…ˆå…³é—­å®ƒä»¬
- è¿”å›ç»“æ„åŒ–çš„JSONæ•°æ®
"""

        # ä½¿ç”¨AIæ‰§è¡Œçˆ¬å–
        logger.info("ğŸ“ STEP 2: è°ƒç”¨Browser-Use AIæ‰§è¡Œå°çº¢ä¹¦çˆ¬å–")
        result = await self.scrape_with_task(
            task=task,
            output_model=XHSNotesCollection,
            max_steps=30  # å°çº¢ä¹¦éœ€è¦å¤šæ­¥æ“ä½œ
        )

        # æ£€æµ‹æ˜¯å¦é‡åˆ°éªŒè¯ç æˆ–ç™»å½•è¦æ±‚
        if result["status"] == "success" and result.get("urls"):
            visited_urls = result["urls"]

            # æ£€æŸ¥æ˜¯å¦è®¿é—®äº†éªŒè¯ç é¡µé¢
            if any("captcha" in url.lower() for url in visited_urls):
                await self._handle_manual_intervention(
                    "âš ï¸  æ£€æµ‹åˆ°éªŒè¯ç ï¼Œè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­å®ŒæˆéªŒè¯ç éªŒè¯",
                    wait_seconds=60,
                    prompt_interval=10
                )
                logger.info("ğŸ”„ é‡æ–°å°è¯•æ‰§è¡Œçˆ¬å–ä»»åŠ¡...")
                result = await self.scrape_with_task(
                    task=task,
                    output_model=XHSNotesCollection,
                    max_steps=30
                )

            # æ£€æŸ¥æ˜¯å¦è®¿é—®äº†ç™»å½•é¡µé¢
            elif any("login" in url.lower() or "signin" in url.lower() for url in visited_urls):
                await self._handle_manual_intervention(
                    "ğŸ” æ£€æµ‹åˆ°ç™»å½•è¦æ±‚ï¼Œè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­å®Œæˆç™»å½•æ“ä½œ",
                    wait_seconds=120,
                    prompt_interval=15
                )
                logger.info("ğŸ”„ é‡æ–°å°è¯•æ‰§è¡Œçˆ¬å–ä»»åŠ¡...")
                result = await self.scrape_with_task(
                    task=task,
                    output_model=XHSNotesCollection,
                    max_steps=30
                )

        logger.info(f"ğŸ“ STEP 3: å¤„ç†AIè¿”å›ç»“æœ | status={result['status']}")

        if result["status"] != "success":
            logger.error(f"âŒ AIçˆ¬å–å°çº¢ä¹¦å¤±è´¥: {result.get('error', 'Unknown error')}")
            logger.error(f"æ‰§è¡Œæ­¥éª¤æ•°: {result.get('steps', 0)}, è®¿é—®çš„URL: {result.get('urls', [])}")
            return []

        # è½¬æ¢ä¸ºXHSNoteå¯¹è±¡
        notes_data = result["data"]
        xhs_notes = []

        # å¤„ç† AI Agent å¤±è´¥è¿”å›å­—ç¬¦ä¸²çš„æƒ…å†µ
        if isinstance(notes_data, str):
            logger.warning(f"âš ï¸  AIè¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸: {type(notes_data)}")
            logger.debug(f"åŸå§‹è¿”å›æ•°æ®: {notes_data}")
            return []

        logger.info(f"AIæˆåŠŸè¿”å› {len(notes_data.notes)} ç¯‡ç¬”è®°æ•°æ®")
        logger.info(f"ğŸ“ STEP 4: è½¬æ¢ç¬”è®°æ•°æ®ä¸ºXHSNoteå¯¹è±¡ | note_count={len(notes_data.notes)}")

        for idx, note_output in enumerate(notes_data.notes):
            note = XHSNote(
                note_id=f"xhs_{attraction_name}_{idx}",
                title=note_output.title,
                author=note_output.author,
                content=note_output.content,
                likes=note_output.likes,
                collects=note_output.collects,
                comments=note_output.comments,
                images=note_output.images[:5],  # æœ€å¤š5å¼ å›¾ç‰‡
                extracted_links=note_output.extracted_links,
                keywords=note_output.keywords,
                created_at=datetime.now().isoformat()  # è½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²
            )
            xhs_notes.append(note)
            logger.debug(f"ç¬”è®° {idx + 1}: {note.title[:30]}... (ç‚¹èµ:{note.likes}, æ”¶è—:{note.collects})")

        logger.info(f"âœ… æˆåŠŸçˆ¬å– {len(xhs_notes)} ç¯‡å°çº¢ä¹¦ç¬”è®°")
        logger.info(f"========== å°çº¢ä¹¦çˆ¬å–å®Œæˆ ==========")
        return xhs_notes

    async def search_destination_guide(self, destination: str, max_attractions: int = 5) -> List[str]:
        """
        æœç´¢ç›®çš„åœ°æ—…æ¸¸æ”»ç•¥ï¼Œæå–æ¨èæ™¯ç‚¹åˆ—è¡¨

        Args:
            destination: ç›®çš„åœ°åŸå¸‚/åœ°åŒº
            max_attractions: æœ€å¤šæå–æ™¯ç‚¹æ•°é‡

        Returns:
            æ¨èæ™¯ç‚¹åç§°åˆ—è¡¨
        """
        logger.info(f"========== å¼€å§‹æœç´¢ç›®çš„åœ°æ”»ç•¥ ==========")
        logger.info(f"ç›®çš„åœ°: {destination}, ç›®æ ‡æ™¯ç‚¹æ•°: {max_attractions}")
        logger.info(f"ğŸ“ STEP 1: å‡†å¤‡ç›®çš„åœ°æ”»ç•¥æœç´¢ä»»åŠ¡ | destination={destination}")

        # æ„å»ºAIä»»åŠ¡æè¿°
        task = f"""
ä»»åŠ¡ï¼šåœ¨å°çº¢ä¹¦æœç´¢"{destination}æ—…æ¸¸æ”»ç•¥"æˆ–"{destination}å¿…å»æ™¯ç‚¹"ï¼Œæå–æ¨èæ™¯ç‚¹åˆ—è¡¨

å…·ä½“æ­¥éª¤ï¼š
1. è®¿é—®å°çº¢ä¹¦ç½‘ç«™ https://www.xiaohongshu.com/search_result?keyword={destination}æ—…æ¸¸æ”»ç•¥ å’Œ https://www.xiaohongshu.com/search_result?keyword={destination}å¿…å»æ™¯ç‚¹
2. ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½(3-5ç§’)
3. æµè§ˆå‰5-10ç¯‡é«˜èµæ”»ç•¥ç¬”è®°
4. ä»è¿™äº›æ”»ç•¥ç¬”è®°ä¸­æå–ï¼š
   - æåˆ°çš„æ™¯ç‚¹åç§°ï¼ˆå¦‚"æ•…å®«"ã€"é•¿åŸ"ã€"é¢å’Œå›­"ç­‰ï¼‰
   - æ¨èç†ç”±ï¼ˆä¸ºä»€ä¹ˆæ¨èè¿™ä¸ªæ™¯ç‚¹ï¼‰
   - ä¼˜å…ˆçº§ï¼ˆæ ¹æ®ç¬”è®°ä¸­çš„æè¿°åˆ¤æ–­ï¼Œå¦‚"å¿…å»"=5ï¼Œ"æ¨è"=4ï¼Œ"å¯é€‰"=3ï¼‰
5. æå–æœ€å¤š{max_attractions}ä¸ªæ™¯ç‚¹

é‡è¦æç¤ºï¼š
- ä¼˜å…ˆé€‰æ‹©ç‚¹èµæ•°å’Œæ”¶è—æ•°è¾ƒé«˜çš„æ”»ç•¥ç¬”è®°
- å¦‚æœé‡åˆ°ç™»å½•è¦æ±‚ï¼Œç›´æ¥åœç•™åœ¨ç™»å½•é¡µé¢ç­‰å¾…ï¼ˆä¸è¦å°è¯•è·³è¿‡æˆ–å…³é—­ç™»å½•çª—å£ï¼Œstatusè¿”å›loginï¼‰
- é‡åˆ°éªŒè¯ç æ—¶ï¼Œåœç•™åœ¨éªŒè¯ç é¡µé¢ï¼ˆä¸è¦å°è¯•è·³è¿‡æˆ–å…³é—­ç™»å½•çª—å£ï¼Œstatusè¿”å›captchaï¼‰
- è¿”å›ç»“æ„åŒ–çš„JSONæ•°æ®
"""

        # ä½¿ç”¨AIæ‰§è¡Œçˆ¬å–
        logger.info("ğŸ“ STEP 2: è°ƒç”¨Browser-Use AIæ‰§è¡Œç›®çš„åœ°æ”»ç•¥çˆ¬å–")
        result = await self.scrape_with_task(
            task=task,
            output_model=DestinationGuide,
            max_steps=30
        )

        # æ­¥éª¤3: å¤„ç†è¿”å›æ•°æ®ï¼ˆscrape_with_taskå·²è‡ªåŠ¨è½¬æ¢ä¸ºPydanticå¯¹è±¡ï¼‰
        guide_data = result["data"]  # â† å·²ç»æ˜¯ DestinationGuide å¯¹è±¡

        # æ£€æµ‹æ˜¯å¦é‡åˆ°éªŒè¯ç æˆ–ç™»å½•è¦æ±‚ï¼ˆé€šè¿‡statuså­—æ®µï¼‰
        if  guide_data.status == "captcha":
            await self._handle_manual_intervention(
                "âš ï¸  æ£€æµ‹åˆ°éªŒè¯ç ï¼Œè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­å®ŒæˆéªŒè¯ç éªŒè¯",
                wait_seconds=60,
                prompt_interval=10
            )
            logger.info("ğŸ”„ é‡æ–°å°è¯•æ‰§è¡Œçˆ¬å–ä»»åŠ¡...")
            result = await self.scrape_with_task(
                task=task,
                output_model=DestinationGuide,
                max_steps=30
            )

        # æ£€æŸ¥æ˜¯å¦è®¿é—®äº†ç™»å½•é¡µé¢
        if  guide_data.status == "login":
            await self._handle_manual_intervention(
                "ğŸ” æ£€æµ‹åˆ°ç™»å½•è¦æ±‚ï¼Œè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­å®Œæˆç™»å½•æ“ä½œ",
                wait_seconds=120,
                prompt_interval=15
            )
            logger.info("ğŸ”„ é‡æ–°å°è¯•æ‰§è¡Œçˆ¬å–ä»»åŠ¡...")
            result = await self.scrape_with_task(
                task=task,
                output_model=DestinationGuide,
                max_steps=30
            )

        logger.info(f"ğŸ“ STEP 3: å¤„ç†AIè¿”å›ç»“æœ | status={result['status']}")

        if result["status"] != "success":
            logger.error(f"âŒ AIçˆ¬å–ç›®çš„åœ°æ”»ç•¥å¤±è´¥: {result.get('error', 'Unknown error')}")
            logger.error(f"æ‰§è¡Œæ­¥éª¤æ•°: {result.get('steps', 0)}, è®¿é—®çš„URL: {result.get('urls', [])}")
            return []

        logger.info(f"AIæˆåŠŸè¿”å› {len(guide_data.recommended_attractions)} ä¸ªæ¨èæ™¯ç‚¹")
        logger.info(f"ğŸ“ STEP 4: æå–æ™¯ç‚¹åç§°åˆ—è¡¨ | attraction_count={len(guide_data.recommended_attractions)}")

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        sorted_attractions = sorted(
            guide_data.recommended_attractions,
            key=lambda x: x.priority,
            reverse=True
        )

        # æå–æ™¯ç‚¹åç§°
        attraction_names = []
        for attr in sorted_attractions[:max_attractions]:
            attraction_names.append(attr.name)
            logger.info(f"  ğŸ“ {attr.name} (ä¼˜å…ˆçº§: {attr.priority}) - {attr.reason[:50]}...")

        logger.info(f"âœ… æˆåŠŸæå– {len(attraction_names)} ä¸ªæ¨èæ™¯ç‚¹")
        logger.info(f"========== ç›®çš„åœ°æ”»ç•¥æœç´¢å®Œæˆ ==========")
        return attraction_names

    async def scrape(self, attraction_name: str, max_notes: int = 10) -> List[XHSNote]:
        """
        å®ç°åŸºç±»çš„æŠ½è±¡æ–¹æ³•

        Args:
            attraction_name: æ™¯ç‚¹åç§°
            max_notes: æœ€å¤§ç¬”è®°æ•°

        Returns:
            ç¬”è®°åˆ—è¡¨
        """
        return await self.search_attraction(attraction_name, max_notes)
