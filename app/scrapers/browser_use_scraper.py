"""åŸºäºBrowser-Useçš„AIé©±åŠ¨çˆ¬è™«åŸºç±»"""
import asyncio
from typing import Optional, Any, TypeVar, Callable, Dict, List, Literal
from browser_use import Agent, BrowserSession, BrowserProfile
from pydantic import BaseModel
from app.llm import LLMFactory
from app.utils.logger import setup_logger
from app.models.prompts import SystemPrompts
from config.settings import settings

logger = setup_logger(__name__)

# æ³›å‹ï¼šæ‰¹é‡çˆ¬å–çš„è¿”å›ç»“æœç±»å‹
T = TypeVar('T')


class BrowserUseScraper:
    """Browser-Use AIé©±åŠ¨çš„çˆ¬è™«åŸºç±»"""

    def __init__(
        self,
        headless: bool = None,
        fast_mode: bool = False,
        keep_alive: bool = False
    ):
        """
        åˆå§‹åŒ–Browser-Useçˆ¬è™«
        Args:
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼
            fast_mode: æ˜¯å¦å¯ç”¨å¿«é€Ÿæ¨¡å¼
            keep_alive: æ˜¯å¦ä¿æŒæµè§ˆå™¨ä¼šè¯
        """
        self.headless = headless if headless is not None else settings.HEADLESS
        self.fast_mode = fast_mode
        self.keep_alive = keep_alive
        self.llm = LLMFactory.create_llm()
        self.active_sessions: List[Any] = []  # è¿½è¸ªæ´»è·ƒçš„æµè§ˆå™¨ä¼šè¯
        self._sessions_lock = asyncio.Lock()  # å¹¶å‘ä¿æŠ¤é”



    def create_browser_profile(self, window_config: Optional[Dict] = None) -> BrowserProfile:
        """
        åˆ›å»ºæµè§ˆå™¨é…ç½®
        Args:
            window_config: å¯é€‰çš„çª—å£é…ç½®ï¼ˆwindow_size, viewportï¼‰
        Returns:
            BrowserProfile å¯¹è±¡
        """
        import uuid
        import time
        from pathlib import Path

        # åŸºç¡€åæ£€æµ‹å‚æ•°
        browser_args = [
            '--disable-blink-features=AutomationControlled',  # éšè—è‡ªåŠ¨åŒ–æ ‡è¯†
            '--disable-dev-shm-usage',
            '--disable-infobars',  # éšè—è‡ªåŠ¨åŒ–ä¿¡æ¯æ 
        ]

        # æ ¹æ®æœ‰å¤´/æ— å¤´æ¨¡å¼æ·»åŠ ä¸åŒå‚æ•°
        if self.headless:
            # æ— å¤´æ¨¡å¼ï¼šæ·»åŠ å¿…è¦å‚æ•°
            browser_args.extend([
                '--no-sandbox',
                '--disable-gpu',
                '--window-size=1920,1080',  # è®¾ç½®çª—å£å¤§å°
            ])
        else:
            # æœ‰å¤´æ¨¡å¼ï¼šæ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
            browser_args.extend([
                '--start-maximized',  # æœ€å¤§åŒ–çª—å£ï¼ˆçœŸå®ç”¨æˆ·è¡Œä¸ºï¼‰
            ])
            logger.info("æœ‰å¤´æ¨¡å¼: æœ€å¤§åŒ–æµè§ˆå™¨çª—å£")

        # Fast Modeä¼˜åŒ–ï¼šå‡å°‘ç­‰å¾…æ—¶é—´ä»¥æå‡é€Ÿåº¦
        if self.fast_mode:
            wait_page_load = 0.1
            wait_actions = 0.1
            logger.info("ğŸš€ Fast Modeå·²å¯ç”¨ï¼šæœ€å°åŒ–ç­‰å¾…æ—¶é—´")
        else:
            wait_page_load = 2.0
            wait_actions = 1.0
            logger.info("ğŸ¢ æ ‡å‡†æ¨¡å¼ï¼šæ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º")

        # æµè§ˆå™¨æ•°æ®å­˜å‚¨é…ç½®
        browser_data_dir = Path("data/browser")
        browser_data_dir.mkdir(parents=True, exist_ok=True)

        # storage_stateï¼šå›ºå®šè·¯å¾„ï¼ˆä¿å­˜ cookiesï¼‰
        storage_state_path = browser_data_dir / "storage_state.json"

        # user_data_dirï¼šéšæœºä¸´æ—¶ç›®å½•
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]
        user_data_path = browser_data_dir / f"tmp_user_data_{timestamp}_{unique_id}"

        logger.info(f"ğŸ“ æµè§ˆå™¨å­˜å‚¨é…ç½®:")
        logger.info(f"   - storage_state: {storage_state_path}")
        logger.info(f"   - user_data_dir: {user_data_path}")

        # æ„å»ºé…ç½®å‚æ•°å­—å…¸
        profile_kwargs = {
            "storage_state": str(storage_state_path),
            "keep_alive": self.keep_alive,
            "headless": self.headless,
            "dom_highlight_elements": True,
            "disable_security": False,
            "user_data_dir": str(user_data_path),
            "args": browser_args,
            "ignore_default_args": ['--enable-automation'],
            "wait_for_network_idle_page_load_time": wait_page_load,
            "wait_between_actions": wait_actions
        }

        # å¦‚æœæœ‰çª—å£é…ç½®ï¼Œåˆå¹¶åˆ°å‚æ•°ä¸­
        if window_config:
            profile_kwargs.update(window_config)  # type: ignore

        profile = BrowserProfile(**profile_kwargs)  # type: ignore

        mode_desc = "Fast Modeï¼ˆé€Ÿåº¦ä¼˜åŒ–ï¼‰" if self.fast_mode else "æ ‡å‡†æ¨¡å¼ï¼ˆåæ£€æµ‹ä¼˜åŒ–ï¼‰"
        logger.info(f"âœ“ æµè§ˆå™¨é…ç½®åˆ›å»ºå®Œæˆï¼ˆ{mode_desc}ï¼‰")
        return profile


    def calculate_window_layout(
        self,
        index: int,
        total_windows: int
    ) -> Optional[Dict]:
        """
        æ ¹æ®çª—å£æ€»æ•°æ™ºèƒ½è®¡ç®—çª—å£å¸ƒå±€ï¼ˆæœ‰å¤´æ¨¡å¼ï¼‰

        Args:
            index: å½“å‰çª—å£ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            total_windows: åŒæ—¶å¯åŠ¨çš„çª—å£æ€»æ•°

        Returns:
            çª—å£é…ç½®å­—å…¸ï¼Œå¦‚æœæ˜¯æ— å¤´æ¨¡å¼åˆ™è¿”å› None
        """
        if self.headless:
            return None

        try:
            import screeninfo
            screen = screeninfo.get_monitors()[0]
            screen_width, screen_height = screen.width, screen.height
        except Exception:
            screen_width, screen_height = 1920, 1080

        # å¸ƒå±€å‚æ•°
        margin = 10
        spacing = 10

        # æ ¹æ®çª—å£æ€»æ•°æ™ºèƒ½è®¡ç®—å¸ƒå±€
        import math

        # ä¼˜å…ˆæ¨ªå‘æ’åˆ—ï¼Œè®¡ç®—æœ€ä¼˜è¡Œåˆ—æ•°
        cols = math.ceil(math.sqrt(total_windows * screen_width / screen_height))
        rows = math.ceil(total_windows / cols)

        # è®¡ç®—çª—å£å°ºå¯¸ï¼ˆè‡ªé€‚åº”å±å¹•ï¼‰
        window_width = (screen_width - 2 * margin - (cols - 1) * spacing) // cols
        window_height = (screen_height - 2 * margin - (rows - 1) * spacing) // rows

        # æœ€å°å°ºå¯¸é™åˆ¶ï¼ˆç¡®ä¿çª—å£å¯ç”¨ï¼‰
        window_width = max(300, window_width)
        window_height = max(400, window_height)

        # è®¡ç®—å½“å‰çª—å£çš„è¡Œåˆ—ä½ç½®
        row = index // cols
        col = index % cols

        # è®¡ç®—çª—å£åç§»é‡
        x_offset = margin + col * (window_width + spacing)
        y_offset = margin + row * (window_height + spacing)

        # è¾¹ç•Œæ£€æŸ¥
        x_offset = min(x_offset, screen_width - window_width - margin)
        y_offset = min(y_offset, screen_height - window_height - margin)

        logger.debug(
            f"   çª—å£å¸ƒå±€ [{index + 1}/{total_windows}]: "
            f"ä½ç½®=({x_offset}, {y_offset}), "
            f"å°ºå¯¸={window_width}x{window_height}, "
            f"ç½‘æ ¼={rows}è¡Œx{cols}åˆ—"
        )

        # æ³¨æ„: window_position è™½ç„¶ä½¿ç”¨ ViewportSize ç±»å‹,ä½† width/height å­—æ®µå®é™…ä»£è¡¨ x/y åæ ‡
        # viewport å‚æ•°åœ¨æœ‰å¤´æ¨¡å¼ä¸‹ä¸éœ€è¦è®¾ç½®(é»˜è®¤ no_viewport=True,å†…å®¹è‡ªé€‚åº”çª—å£)
        return {
            "window_size": {"width": window_width, "height": window_height},
            "window_position": {"width": x_offset, "height": y_offset},  # width=x, height=y
        }

    async def scrape_batch(
        self,
        items: List[str],
        scrape_task_fn: Callable[[str], str],
        parse_result_fn: Callable[[Any], T],
        output_model: type[BaseModel],
        max_concurrent: int = 5,
        max_steps: int = 30,
        item_label: str = "item"
    ) -> Dict[str, T]:
        """
        é€šç”¨æ‰¹é‡å¹¶å‘çˆ¬å–æ–¹æ³•

        Args:
            items: å¾…çˆ¬å–é¡¹ç›®åˆ—è¡¨ï¼ˆå¦‚æ™¯ç‚¹åç§°åˆ—è¡¨ï¼‰
            scrape_task_fn: ç”Ÿæˆä»»åŠ¡æç¤ºè¯çš„å‡½æ•° (item_name -> task_string)
            parse_result_fn: è§£æç»“æœçš„å‡½æ•° (raw_result -> parsed_result)
            output_model: Pydantic è¾“å‡ºæ¨¡å‹
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            max_steps: æ¯ä¸ªä»»åŠ¡çš„æœ€å¤§æ­¥éª¤æ•°
            item_label: é¡¹ç›®æ ‡ç­¾ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            å­—å…¸ {item_name: parsed_result}
        """
        logger.info("=" * 60)
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¹¶å‘çˆ¬å–")
        logger.info(f"   {item_label}æ•°é‡: {len(items)}")
        logger.info(f"   æœ€å¤§å¹¶å‘æ•°: {max_concurrent}")
        logger.info("=" * 60)

        # åˆ›å»ºçª—å£ä½ç½®æ± ï¼ˆé¢„å…ˆè®¡ç®—å¥½æ‰€æœ‰ä½ç½®ï¼‰
        position_pool: asyncio.Queue = asyncio.Queue()
        for i in range(max_concurrent):
            window_config = self.calculate_window_layout(i, max_concurrent)
            await position_pool.put(window_config)
        logger.info(f"   âœ“ çª—å£ä½ç½®æ± åˆå§‹åŒ–å®Œæˆï¼ˆ{max_concurrent} ä¸ªä½ç½®ï¼‰")

        semaphore = asyncio.Semaphore(max_concurrent)

        async def scrape_with_semaphore(item_name: str):
            """ä¸ºå•ä¸ªé¡¹ç›®çˆ¬å–ï¼ˆå¤ç”¨ scrape() æ–¹æ³•ï¼‰"""
            # ä»æ± ä¸­å€Ÿç”¨çª—å£ä½ç½®
            window_config = await position_pool.get()
            try:
                async with semaphore:
                    logger.info(f"ğŸ“ å¼€å§‹çˆ¬å–: {item_name}")

                    # ç”Ÿæˆä»»åŠ¡
                    task = scrape_task_fn(item_name)

                    # è°ƒç”¨ scrape() æ–¹æ³•
                    result = await self.scrape(
                        task=task,
                        output_model=output_model,
                        max_steps=max_steps,
                        use_vision=False,  # ç¦ç”¨è§†è§‰èƒ½åŠ›ä»¥é¿å…æˆªå›¾è¶…æ—¶
                        window_config=window_config
                    )

                    # è§£æç»“æœ
                    if result["status"] == "success" and result.get("is_successful"):
                        parsed_result = parse_result_fn(result["data"])
                        logger.info(f"   âœ… æˆåŠŸ: {item_name}")
                        return item_name, parsed_result
                    else:
                        logger.warning(f"   âŒ å¤±è´¥: {item_name}")
                        return item_name, None
            finally:
                # å½’è¿˜çª—å£ä½ç½®åˆ°æ± ä¸­
                await position_pool.put(window_config)

        # å¹¶å‘æ‰§è¡Œ
        tasks = [scrape_with_semaphore(name) for name in items]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # æ±‡æ€»ç»“æœ
        result_dict: Dict[str, T] = {}
        success_count = 0
        fail_count = 0

        for result in results:
            if isinstance(result, Exception):
                logger.error(f"   ä»»åŠ¡å¼‚å¸¸: {result}")
                fail_count += 1
            elif isinstance(result, tuple) and len(result) == 2:
                item_name, parsed_data = result
                result_dict[item_name] = parsed_data
                if parsed_data is not None:
                    success_count += 1
                else:
                    fail_count += 1
            else:
                logger.error(f"   ç»“æœæ ¼å¼å¼‚å¸¸: {result}")
                fail_count += 1

        logger.info("=" * 60)
        logger.info(f"âœ… æ‰¹é‡çˆ¬å–å®Œæˆ")
        logger.info(f"   æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, æ€»è®¡: {len(items)}")
        logger.info("=" * 60)

        return result_dict

    def _log_agent_steps(self, history):
        """è¯¦ç»†è®°å½• Agent æ‰§è¡Œçš„æ¯ä¸€æ­¥"""
        logger.info("=" * 60)
        logger.info("ğŸ” AI Agent æ‰§è¡Œæ­¥éª¤è¯¦æƒ…")
        logger.info("=" * 60)

        for i, step_history in enumerate(history.history, 1):
            logger.info(f"\nğŸ“ Step {i}/{len(history.history)}:")

            # è®°å½•è¯„ä¼°ç»“æœ
            if hasattr(step_history, 'model_output') and step_history.model_output:
                model_output = step_history.model_output

                # è·å–è¯„ä¼°ç»“æœï¼ˆå…¼å®¹ä¸åŒç‰ˆæœ¬çš„ browser-useï¼‰
                evaluation = getattr(model_output, 'evaluation_previous_goal', None) or getattr(model_output,
                                                                                                'evaluation', None)
                if evaluation:
                    logger.info(f"   âš–ï¸  è¯„ä¼°: {evaluation}")

                    # ğŸ”´ æ£€æµ‹å…³é”®å¤±è´¥åŸå› 
                    eval_lower = str(evaluation).lower()
                    if 'security' in eval_lower or 'restriction' in eval_lower:
                        logger.error("   ğŸš« æ£€æµ‹åˆ°å®‰å…¨é™åˆ¶ï¼ˆåçˆ¬è™«æ‹¦æˆªï¼‰")
                    if 'captcha' in eval_lower:
                        logger.error("   ğŸš« æ£€æµ‹åˆ°éªŒè¯ç æŒ‘æˆ˜")
                    if 'failure' in eval_lower or 'failed' in eval_lower:
                        logger.warning("   âš ï¸  æ­¥éª¤æ‰§è¡Œå¤±è´¥")

                # è®°å½•ä¸‹ä¸€æ­¥ç›®æ ‡ï¼ˆç›´æ¥ä» Pydantic å¯¹è±¡è·å–å±æ€§ï¼‰
                next_goal = getattr(model_output, 'next_goal', None)
                if next_goal:
                    logger.info(f"   ğŸ¯ ä¸‹ä¸€æ­¥ç›®æ ‡: {next_goal}")

            # è®°å½•æ‰§è¡Œçš„åŠ¨ä½œ
            if hasattr(step_history, 'action_result') and step_history.action_result:
                actions = step_history.action_result
                if isinstance(actions, list):
                    for action in actions:
                        action_name = getattr(action, 'action_name', 'unknown')
                        logger.info(f"   ğŸ¦¾ æ‰§è¡ŒåŠ¨ä½œ: {action_name}")
                else:
                    logger.info(f"   ğŸ¦¾ æ‰§è¡ŒåŠ¨ä½œ: {actions}")

            # è®°å½•è®¿é—®çš„ URL
            if hasattr(step_history, 'state') and hasattr(step_history.state, 'url'):
                url = step_history.state.url
                logger.info(f"   ğŸ”— å½“å‰é¡µé¢: {url}")

        logger.info("\n" + "=" * 60)

        # æœ€ç»ˆç»“æœæ‘˜è¦
        final_result = history.final_result()
        if final_result:
            logger.info(f"ğŸ“„ æœ€ç»ˆç»“æœ: {final_result}")
        else:
            logger.warning("âš ï¸  æœªè·å–åˆ°æœ€ç»ˆç»“æœ")

        logger.info("=" * 60)

    async def scrape(
            self,
            task: str,
            output_model: Optional[type[BaseModel]] = None,
            max_steps: int = 20,
            use_vision: bool | Literal['auto']  = False,  # é»˜è®¤ç¦ç”¨è§†è§‰èƒ½åŠ›
            window_config: Optional[Dict] = None
    ) -> dict:
        """
        ä½¿ç”¨Browser-Use Agentæ‰§è¡Œçˆ¬å–ä»»åŠ¡

        Args:
            task: ä»»åŠ¡æè¿°ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
            output_model: Pydanticæ¨¡å‹ç±»ï¼Œç”¨äºç»“æ„åŒ–è¾“å‡º
            max_steps: æœ€å¤§æ­¥éª¤æ•°
            use_vision: æ˜¯å¦ä½¿ç”¨è§†è§‰èƒ½åŠ›ï¼ˆæˆªå›¾ç†è§£ï¼‰
            window_config: çª—å£é…ç½®ï¼ˆæ‰¹é‡çˆ¬å–æ—¶ä¼ å…¥ï¼‰

        Returns:
            çˆ¬å–ç»“æœå­—å…¸
        """
        logger.info(f"ğŸ“ STEP 4: å¼€å§‹AIçˆ¬å–ä»»åŠ¡ | max_steps={max_steps}, use_vision={use_vision}")

        logger.info(
            f"ä»»åŠ¡é…ç½®: max_steps={max_steps}, use_vision={use_vision}, output_model={output_model.__name__ if output_model else 'None'}")
        logger.debug(f"å®Œæ•´ä»»åŠ¡æè¿°:\n{task}")

        # åˆ›å»ºæµè§ˆå™¨é…ç½®ï¼ˆæ”¯æŒä¼ å…¥çª—å£é…ç½®ï¼‰
        browser_profile = self.create_browser_profile(window_config)
        browser_session = BrowserSession(browser_profile=browser_profile)

        # æ³¨å†Œæµè§ˆå™¨ä¼šè¯åˆ°æ´»è·ƒåˆ—è¡¨ï¼ˆå¹¶å‘å®‰å…¨ï¼‰
        async with self._sessions_lock:
            self.active_sessions.append(browser_session)

        try:
            logger.info("ğŸ“ STEP 5: åˆ›å»ºAI Agent")
            # Fast Modeä¼˜åŒ–ï¼šæ·»åŠ é€Ÿåº¦ä¼˜åŒ–æç¤ºè¯å’Œflash_mode
            agent_kwargs = {
                "task": task,
                "llm": self.llm,
                "browser_session": browser_session,
                "output_model_schema": output_model,
                "use_vision": use_vision,
            }

            if self.fast_mode:
                agent_kwargs["flash_mode"] = True  # ç¦ç”¨LLM thinkingä»¥æå‡é€Ÿåº¦
                agent_kwargs["extend_system_message"] = SystemPrompts.SPEED_OPTIMIZATION
                logger.info("ğŸš€ Fast Mode: flash_mode=True, é€Ÿåº¦ä¼˜åŒ–æç¤ºè¯å·²åº”ç”¨")

            agent = Agent(**agent_kwargs)

            mode_desc = "Fast Modeï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰" if self.fast_mode else "æ ‡å‡†æ¨¡å¼ï¼ˆè´¨é‡ä¼˜å…ˆï¼‰"
            logger.info(f"   âœ“ AI Agentåˆ›å»ºæˆåŠŸï¼ˆ{mode_desc}ï¼‰")

            logger.info(f"ğŸ“ STEP 6: æ‰§è¡ŒAIè‡ªåŠ¨åŒ–ä»»åŠ¡ | timeout={settings.MAX_SCRAPE_TIMEOUT}s")
            logger.info("   ğŸ¤– AIå¼€å§‹æ§åˆ¶æµè§ˆå™¨...")

            # æ‰§è¡Œä»»åŠ¡
            history = await asyncio.wait_for(
                agent.run(max_steps=max_steps),
                timeout=settings.MAX_SCRAPE_TIMEOUT
            )

            # æå–ç»“æœ
            result: Any = history.final_result()

            # æ”¶é›†è®¿é—®çš„URL
            visited_urls = [item.state.url for item in history.history if hasattr(item.state, 'url')]

            logger.info(f"   âœ… AIçˆ¬å–æˆåŠŸï¼Œæ‰§è¡Œäº† {len(history.history)} æ­¥")
            logger.info(f"è®¿é—®çš„é¡µé¢: {visited_urls}")

            # è¯¦ç»†è®°å½•æ¯ä¸€æ­¥çš„æ‰§è¡Œæƒ…å†µ
            self._log_agent_steps(history)

            # ğŸ”§ è‡ªåŠ¨ç±»å‹è½¬æ¢ï¼šå¦‚æœæŒ‡å®šäº† output_modelï¼Œå°† JSON å­—ç¬¦ä¸²è½¬æ¢ä¸º Pydantic å¯¹è±¡
            if output_model and result:
                try:
                    if isinstance(result, str):
                        # Browser-Use è¿”å›çš„æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œè‡ªåŠ¨è½¬æ¢ä¸º Pydantic å¯¹è±¡
                        result = output_model.model_validate_json(result)
                        logger.debug(f"âœ“ è‡ªåŠ¨è½¬æ¢ JSON â†’ {output_model.__name__} å¯¹è±¡")
                    elif isinstance(result, dict):
                        # å¦‚æœæ˜¯å­—å…¸ï¼Œä½¿ç”¨ model_validate
                        result = output_model.model_validate(result)
                        logger.debug(f"âœ“ è‡ªåŠ¨è½¬æ¢ dict â†’ {output_model.__name__} å¯¹è±¡")
                    # else: å·²ç»æ˜¯ Pydantic å¯¹è±¡ï¼Œæ— éœ€è½¬æ¢
                except Exception as e:
                    logger.warning(f"âš ï¸  è‡ªåŠ¨ç±»å‹è½¬æ¢å¤±è´¥: {e}ï¼Œè¿”å›åŸå§‹æ•°æ®")
                    # è½¬æ¢å¤±è´¥æ—¶ä¿æŒåŸå§‹æ•°æ®

            return {
                "is_successful": history.is_successful(),  ### æ˜¯å¦æˆåŠŸ
                "status": "success",
                "data": result,  # â† ç°åœ¨æ˜¯ Pydantic å¯¹è±¡ï¼ˆå¦‚æœæŒ‡å®šäº† output_modelï¼‰
                "steps": len(history.history),
                "urls": visited_urls,
                "done": history.is_done(),
            }

        except asyncio.TimeoutError:
            logger.error(f"âŒ AIçˆ¬å–è¶…æ—¶: {settings.MAX_SCRAPE_TIMEOUT}ç§’")
            return {
                "is_successful": False,
                "status": "timeout",
                "error": f"Task exceeded {settings.MAX_SCRAPE_TIMEOUT}s timeout"
            }
        except Exception as e:
            logger.exception(f"âŒ AIçˆ¬å–å¤±è´¥: {e}")
            return {
                "is_successful": False,
                "status": "error",
                "error": str(e)
            }
        finally:
            # å…³é—­æµè§ˆå™¨ä¼šè¯
            try:
                await browser_session.stop()
                # ä»æ´»è·ƒåˆ—è¡¨ä¸­ç§»é™¤ï¼ˆå¹¶å‘å®‰å…¨ï¼‰
                async with self._sessions_lock:
                    if browser_session in self.active_sessions:
                        self.active_sessions.remove(browser_session)
                logger.debug("âœ“ æµè§ˆå™¨ä¼šè¯å·²å…³é—­")
            except Exception as e:
                logger.warning(f"âš ï¸  å…³é—­æµè§ˆå™¨è­¦å‘Š: {e}")

    async def close(self):
        """å…³é—­æ‰€æœ‰æ´»è·ƒçš„æµè§ˆå™¨ä¼šè¯"""
        if not self.active_sessions:
            logger.debug("æ— éœ€æ¸…ç†ï¼ˆæ²¡æœ‰æ´»è·ƒçš„æµè§ˆå™¨ä¼šè¯ï¼‰")
            return

        # è·å–ä¼šè¯å‰¯æœ¬å¹¶æ¸…ç©ºé›†åˆï¼ˆå¹¶å‘å®‰å…¨ï¼‰
        async with self._sessions_lock:
            sessions_to_close = list(self.active_sessions)
            self.active_sessions.clear()

        logger.info(f"ğŸ§¹ å…³é—­ {len(sessions_to_close)} ä¸ªæµè§ˆå™¨ä¼šè¯...")
        for i, session in enumerate(sessions_to_close, 1):
            try:
                await session.stop()
                logger.debug(f"   âœ“ [{i}/{len(sessions_to_close)}] æµè§ˆå™¨ä¼šè¯å·²å…³é—­")
            except Exception as e:
                logger.warning(f"   âš ï¸ [{i}/{len(sessions_to_close)}] å…³é—­ä¼šè¯è­¦å‘Š: {e}")

        logger.info("âœ… æµè§ˆå™¨èµ„æºæ¸…ç†å®Œæˆ")


